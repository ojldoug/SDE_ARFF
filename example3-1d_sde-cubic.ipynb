{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import ipynbname\n",
    "script_dir = os.getcwd()\n",
    "filename = ipynbname.name()\n",
    "\n",
    "from sde.sde_learning_network_modified import (\n",
    "    TimingCallback,\n",
    "    SDEIdentification,\n",
    "    ModelBuilder,\n",
    "    SDEApproximationNetwork,\n",
    ")\n",
    "\n",
    "from sde.experiment_reports_owen import (\n",
    "    PlotResults,\n",
    "    sample_data\n",
    ")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook parameters\n",
    "n_dimensions = 1\n",
    "step_size = 1e-2\n",
    "n_pts = 10000\n",
    "n_subsample = 1000\n",
    "\n",
    "random_seed = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network parameters\n",
    "n_layers = 1\n",
    "n_dim_per_layer = 2**7\n",
    "\n",
    "#ACTIVATIONS = tf.nn.elu\n",
    "def ACTIVATIONS(x):\n",
    "    j = tf.constant(1j, dtype=tf.complex64)\n",
    "    x = tf.cast(x, dtype=tf.complex64)\n",
    "    return tf.exp(j * x)\n",
    "VALIDATION_SPLIT = .1\n",
    "BATCH_SIZE = 2**3\n",
    "LEARNING_RATE = 1e-3\n",
    "N_EPOCHS = 200\n",
    "\n",
    "diffusivity_type = \"diagonal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate training data\n",
    "def true_drift(x):\n",
    "    result = -(4 * x**3 - 8 * x + 3) / 2\n",
    "    return result.reshape(-1, 1)\n",
    "\n",
    "\n",
    "def true_diffusion(x):\n",
    "    result = (0.1 * x + 1) * 0.5\n",
    "    return result.reshape(-1, 1)\n",
    "\n",
    "\n",
    "def true_drift_diffusion(x):\n",
    "    return true_drift(x), true_diffusion(x)\n",
    "\n",
    "\n",
    "xlim = np.array([[-2, 2]])\n",
    "\n",
    "step_sizes = np.zeros((n_pts, 1)) + step_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 10:09:21.568192: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2025-06-07 10:09:21.568225: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: KW61146\n",
      "2025-06-07 10:09:21.568231: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: KW61146\n",
      "2025-06-07 10:09:21.568317: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 560.35.3\n",
      "2025-06-07 10:09:21.568338: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 560.35.3\n",
      "2025-06-07 10:09:21.568343: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 560.35.3\n",
      "2025-06-07 10:09:21.568528: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for 200 epochs with 9000 data points, validating with 1000\n",
      "WARNING:tensorflow:From /home/douglaoj/miniconda3/envs/SDE_NN/lib/python3.9/site-packages/tensorflow_probability/python/distributions/distribution.py:342: calling MultivariateNormalDiag.__init__ (from tensorflow_probability.python.distributions.mvn_diag) with scale_identity_multiplier is deprecated and will be removed after 2020-01-01.\n",
      "Instructions for updating:\n",
      "`scale_identity_multiplier` is deprecated; please combine it into `scale_diag` directly instead.\n",
      "training for 200 epochs with 9000 data points, validating with 1000\n",
      "training for 200 epochs with 9000 data points, validating with 1000\n",
      "training for 200 epochs with 9000 data points, validating with 1000\n",
      "training for 200 epochs with 9000 data points, validating with 1000\n",
      "training for 200 epochs with 9000 data points, validating with 1000\n",
      "training for 200 epochs with 9000 data points, validating with 1000\n",
      "training for 200 epochs with 9000 data points, validating with 1000\n",
      "training for 200 epochs with 9000 data points, validating with 1000\n",
      "training for 200 epochs with 9000 data points, validating with 1000\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "No_of_tests = 10\n",
    "cumulative_times = np.zeros((No_of_tests, N_EPOCHS))\n",
    "losses = np.zeros((No_of_tests, N_EPOCHS))\n",
    "val_losses = np.zeros((No_of_tests, N_EPOCHS))\n",
    "training_time = np.zeros(No_of_tests)\n",
    "val_loss = np.zeros(No_of_tests)\n",
    "\n",
    "for i in range(No_of_tests):\n",
    "    rng = np.random.default_rng(random_seed+i)\n",
    "    tf.random.set_seed(random_seed+i)\n",
    "\n",
    "    # generate data\n",
    "    x_data, y_data, _ = sample_data(true_drift_diffusion, step_size, n_pts, n_subsample, rng, xlim)\n",
    "\n",
    "    # build network\n",
    "    encoder = ModelBuilder.define_gaussian_process(\n",
    "                                        n_input_dimensions=n_dimensions,\n",
    "                                        n_output_dimensions=n_dimensions,\n",
    "                                        n_layers=n_layers,\n",
    "                                        n_dim_per_layer=n_dim_per_layer,\n",
    "                                        name=\"GP\",\n",
    "                                        activation=ACTIVATIONS,\n",
    "                                        diffusivity_type=diffusivity_type)\n",
    "    model = SDEApproximationNetwork(sde_model=encoder, method=\"euler\")\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adamax())\n",
    "    sde_i = SDEIdentification(model=model)\n",
    "    timing_callback = TimingCallback()\n",
    "\n",
    "    # train network\n",
    "    hist, _ = sde_i.train_model(x_data, y_data, step_size=step_sizes, validation_split=VALIDATION_SPLIT, n_epochs=N_EPOCHS, batch_size=BATCH_SIZE, callbacks=[timing_callback])\n",
    "    \n",
    "    cumulative_times[i,:] = timing_callback.epoch_times\n",
    "    losses[i,:] = hist.history[\"loss\"]\n",
    "    val_losses[i,:] = hist.history[\"val_loss\"]\n",
    "\n",
    "    moving_avg = np.zeros(N_EPOCHS)\n",
    "    min_moving_avg = float('inf')\n",
    "    moving_avg_len = 5\n",
    "    min_index = 0\n",
    "    break_iterations = 5\n",
    "    for j in range(N_EPOCHS):\n",
    "        if j < moving_avg_len:\n",
    "            moving_avg[j] = np.mean(val_losses[i,:j+1])\n",
    "        else:\n",
    "            moving_avg[j] = np.mean(val_losses[i,j-moving_avg_len+1:j+1])\n",
    "\n",
    "        if moving_avg[j] < min_moving_avg:\n",
    "            min_moving_avg = moving_avg[j]\n",
    "            min_index = j\n",
    "\n",
    "        if min_index + break_iterations < j:\n",
    "            break\n",
    "\n",
    "    val_loss_array = val_losses[i,:j]\n",
    "    val_loss_min_index = np.argmin(val_loss_array)\n",
    "    training_time[i] = cumulative_times[i,val_loss_min_index]\n",
    "    val_loss[i] = val_losses[i,val_loss_min_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PlotResults' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# display and save plots\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m PR \u001b[38;5;241m=\u001b[39m \u001b[43mPlotResults\u001b[49m(script_dir\u001b[38;5;241m=\u001b[39mscript_dir, filename\u001b[38;5;241m=\u001b[39mfilename, n_subsample\u001b[38;5;241m=\u001b[39mn_subsample)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# calculate theoretical mean min loss (integral over loss function across input domain)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m PR\u001b[38;5;241m.\u001b[39mmean_min_loss(true_diffusion, n_pts, validation_split, step_size, vlim, plim\u001b[38;5;241m=\u001b[39mxlim, save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PlotResults' is not defined"
     ]
    }
   ],
   "source": [
    "# display and save plots\n",
    "PR = PlotResults(script_dir=script_dir, filename=filename, n_subsample=n_subsample)\n",
    "\n",
    "if No_of_tests > 1:\n",
    "    PR.loss_stats(training_time, val_loss, save=True)\n",
    "    \n",
    "PR.loss_v_time(cumulative_times, val_losses, save=True)\n",
    "\n",
    "PR.plot_results_functions(sde_i.drift_diffusivity, true_drift_diffusion, x_data, save=False)\n",
    "\n",
    "time = 100*step_size\n",
    "PR.plot_histogram(sde_i.drift_diffusivity, step_size, time, rng, xlim, name='Adam', save=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"GP_gaussian_process\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " GP_inputs (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " GP_mean_hidden_0 (Dense)       (None, 128)          256         ['GP_inputs[0][0]']              \n",
      "                                                                                                  \n",
      " GP_std_hidden_0 (Dense)        (None, 128)          256         ['GP_inputs[0][0]']              \n",
      "                                                                                                  \n",
      " GP_output_mean (Dense)         (None, 1)            129         ['GP_mean_hidden_0[0][0]']       \n",
      "                                                                                                  \n",
      " GP_output_std (Dense)          (None, 1)            129         ['GP_std_hidden_0[0][0]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 770\n",
      "Trainable params: 770\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (SDE_NN)",
   "language": "python",
   "name": "sde_nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
