{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3433b2a5-bc94-40e6-a363-c33d787043b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 18:45:09.542962: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-25 18:45:09.547362: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu:/usr/local/cuda-12.6/lib64::/usr/lib/x86_64-linux-gnu\n",
      "2025-05-25 18:45:09.547375: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import ipynbname\n",
    "script_dir = os.getcwd()\n",
    "filename = ipynbname.name()\n",
    "\n",
    "from sde.SDE_ARFF_lib import (\n",
    "    SDEARFFTrain,\n",
    "    NNHyperparameters,\n",
    "    MeanMinLoss\n",
    ")\n",
    "\n",
    "from sde.experiment_reports import (\n",
    "    sample_data,\n",
    "    plot_results_functions,\n",
    "    histogram_data,\n",
    "    plot_histogram\n",
    ")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43226dc4-e55e-4954-b798-63fab6892e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook parameters\n",
    "n_dimensions = 3\n",
    "step_size = .25\n",
    "n_pts = 20000\n",
    "n_subsample = 1000\n",
    "\n",
    "random_seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95cdf4d-9d91-48ab-ad54-433e0fd5f58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network parameters\n",
    "validation_split = .1\n",
    "ARFF_validation_split = .1\n",
    "\n",
    "drift_param = NNHyperparameters(K=2**7, \n",
    "                                M_min=10,\n",
    "                                M_max=500,\n",
    "                                lambda_reg=2e-6,\n",
    "                                gamma=1,\n",
    "                                delta=0.1,\n",
    "                                name='drift')\n",
    "diff_param = NNHyperparameters(K=drift_param.K,\n",
    "                               M_min=drift_param.M_min,\n",
    "                               M_max=drift_param.M_max,\n",
    "                               lambda_reg=drift_param.lambda_reg,\n",
    "                               gamma=drift_param.gamma,\n",
    "                               delta=drift_param.delta,\n",
    "                               name='diff')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb4aacb2-522f-46a2-84cf-36a62a1a845d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02045836 0.03502162 0.02678421]\n",
      " [0.03502162 0.06355898 0.02981971]\n",
      " [0.02678421 0.02981971 0.12453806]]\n",
      "data shape (20000, 3)\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE 2\n",
    "def f_1(x):\n",
    "    A = 0\n",
    "    B = np.array([[-1], [0], [0]])\n",
    "    C = np.array([[0], [0], [0]])\n",
    "    D = np.array([[0], [0], [0]])\n",
    "    f = np.squeeze(A + np.dot(x, B) + np.dot(np.square(x), C) + np.dot(np.power(x, 3), D))\n",
    "    return f\n",
    "\n",
    "\n",
    "def f_2(x):\n",
    "    A = 0\n",
    "    B = np.array([[0], [-1], [0]])\n",
    "    C = np.array([[0], [0], [0]])\n",
    "    D = np.array([[0], [0], [0]])\n",
    "    f = np.squeeze(A + np.dot(x, B) + np.dot(np.square(x), C) + np.dot(np.power(x, 3), D))\n",
    "    return f\n",
    "\n",
    "\n",
    "def f_3(x):\n",
    "    A = 0\n",
    "    B = np.array([[0], [0], [-1]])\n",
    "    C = np.array([[0], [0], [0]])\n",
    "    D = np.array([[0], [0], [0]])\n",
    "    f = np.squeeze(A + np.dot(x, B) + np.dot(np.square(x), C) + np.dot(np.power(x, 3), D))\n",
    "    return f\n",
    "\n",
    "\n",
    "def true_drift(x):\n",
    "    drift = np.transpose(np.array([f_1(x), f_2(x), f_3(x)]))\n",
    "    return drift\n",
    "\n",
    "\n",
    "def sigma_11(x):\n",
    "    A = 0.02045836\n",
    "    B = np.array([[0], [0], [0]])\n",
    "    C = np.array([[0], [0], [0]])\n",
    "    D = np.array([[0], [0], [0]])\n",
    "    sigma = np.squeeze(A + np.dot(x, B) + np.dot(np.square(x), C) + np.dot(np.power(x, 3), D))\n",
    "    return sigma\n",
    "\n",
    "\n",
    "def sigma_12(x):\n",
    "    A = -0.03502162\n",
    "    B = np.array([[0], [0], [0]])\n",
    "    C = np.array([[0], [0], [0]])\n",
    "    D = np.array([[0], [0], [0]])\n",
    "    sigma = np.squeeze(A + np.dot(x, B) + np.dot(np.square(x), C) + np.dot(np.power(x, 3), D))\n",
    "    return sigma\n",
    "\n",
    "\n",
    "def sigma_13(x):\n",
    "    A = -0.02678421\n",
    "    B = np.array([[0], [0], [0]])\n",
    "    C = np.array([[0], [0], [0]])\n",
    "    D = np.array([[0], [0], [0]])\n",
    "    sigma = np.squeeze(A + np.dot(x, B) + np.dot(np.square(x), C) + np.dot(np.power(x, 3), D))\n",
    "    return sigma\n",
    "\n",
    "\n",
    "def sigma_22(x):\n",
    "    A = 0.06355898\n",
    "    B = np.array([[0], [0], [0]])\n",
    "    C = np.array([[0], [0], [0]])\n",
    "    D = np.array([[0], [0], [0]])\n",
    "    sigma = np.squeeze(A + np.dot(x, B) + np.dot(np.square(x), C) + np.dot(np.power(x, 3), D))\n",
    "    return sigma\n",
    "\n",
    "\n",
    "def sigma_23(x):\n",
    "    A = 0.02981971\n",
    "    B = np.array([[0], [0], [0]])\n",
    "    C = np.array([[0], [0], [0]])\n",
    "    D = np.array([[0], [0], [0]])\n",
    "    sigma = np.squeeze(A + np.dot(x, B) + np.dot(np.square(x), C) + np.dot(np.power(x, 3), D))\n",
    "    return sigma\n",
    "\n",
    "\n",
    "def sigma_33(x):\n",
    "    A = 0.12453806\n",
    "    B = np.array([[0], [0], [0]])\n",
    "    C = np.array([[0], [0], [0]])\n",
    "    D = np.array([[0], [0], [0]])\n",
    "    sigma = np.squeeze(A + np.dot(x, B) + np.dot(np.square(x), C) + np.dot(np.power(x, 3), D))\n",
    "    return sigma\n",
    "\n",
    "\n",
    "def true_diffusion(x):\n",
    "    diffusion = np.abs(np.transpose(np.array([[sigma_11(x), sigma_12(x), sigma_13(x)], [sigma_12(x), sigma_22(x), sigma_23(x)], [sigma_13(x), sigma_23(x), sigma_33(x)]])))\n",
    "    return diffusion\n",
    "\n",
    "\n",
    "def true_drift_diffusion(x, param=None):\n",
    "    return true_drift(x), true_diffusion(x)\n",
    "\n",
    "\n",
    "print(true_diffusion((0,0,0)))\n",
    "\n",
    "xlim = np.array([[-1, 1], [-1, 1], [-1, 1]])\n",
    "\n",
    "step_sizes = np.zeros((n_pts, 1)) + step_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4891d1-5910-453d-8384-008a481edb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train networks\n",
    "No_of_tests = 10\n",
    "training_time = np.zeros(No_of_tests)\n",
    "val_loss = np.zeros(No_of_tests)\n",
    "\n",
    "for i in range(No_of_tests):\n",
    "    rng = np.random.default_rng(random_seed + i)\n",
    "\n",
    "    # generate data\n",
    "    x_data, y_data, _ = sample_data(true_drift_diffusion, step_size, n_pts, n_subsample, rng, xlim)\n",
    "\n",
    "    # build network\n",
    "    SAT = SDEARFFTrain(n_dimensions=n_dimensions, diff_type=\"symmetric\", rng=rng, resampling=True)\n",
    "\n",
    "    # train network\n",
    "    hist = SAT.train_model(drift_param, diff_param, true_drift, true_diffusion, x_data, y_data, step_sizes=step_sizes, validation_split=validation_split, ARFF_validation_split=ARFF_validation_split, plot=False)\n",
    "    \n",
    "    training_time[i] = hist.history[\"training_time\"]\n",
    "    val_loss[i] = hist.history[\"val_loss\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55cbf6e-3bcb-48b0-a8c5-a6eefbc38c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display and save plots\n",
    "PR = PlotResults(script_dir=script_dir, filename=filename, n_subsample=n_subsample)\n",
    "\n",
    "# calculate theoretical mean min loss (integral over loss function across input domain)\n",
    "PR.mean_min_loss(true_diffusion, n_pts, validation_split, step_size, xlim, save=True)\n",
    "\n",
    "if No_of_tests > 1:\n",
    "    PR.loss_stats(training_time, val_loss, save=True)\n",
    "\n",
    "PR.plot_results_functions(SAT.drift_diffusion, true_drift_diffusion, x_data, save=True)\n",
    "\n",
    "time = 100*step_size\n",
    "PR.plot_histogram(true_drift_diffusion, step_size, time, rng, xlim, name='True', save=True)\n",
    "PR.plot_histogram(SAT.drift_diffusion, step_size, time, rng, xlim, name='ARFF', save=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (SDE_NN)",
   "language": "python",
   "name": "sde_nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
